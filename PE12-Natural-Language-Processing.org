* <<<CP1224>>> NATURAL LANGUAGE PROCESSING
:Properties:
:author:  B Senthil Kumar, D Thenmozhi
:date: 06 May 2022
:end:

#+startup: showall

{{{credits}}}
|L|T|P|C|
|3|0|0|3|

** Course Objectives
- To learn the language models.
- To understand the levels of knowledge in language processing.
- To explore text processing using Python.
- To understand the NLP applications. 

{{{unit}}}
|Unit I |Overview and Language Modeling|9| 
Regular Expressions -- Text Normalization -- N-grams -- Evaluating language model -- Sampling -- Generalization -- Smoothing -- Vector Semantics: Words and vectors -- Cosine similarity -- TF-IDF -- PPMI -- Word2Vec -- Semantic properties of embeddings -- Evaluating vector model -- Neural language model: Feedforward networks for NLP -- Feedforward Neural Language Modeling -- Training the neural language model

{{{unit}}} 
|Unit II|Word Level and Syntactic Analysis|9| 
English Word Classes -- Part-of-Speech Tagging -- Named Entities -- NE Tagging -- Context-free grammar -- Grammar rules for Engligh -- Treebanks -- Constituency Parsing: Ambiguity -- CKY Parsing -- Neural Constituency Parsing -- Dependency Parsing: Dependency Relations -- Formalisms -- Transition-based and Graph-based Dependency Parsing


{{{unit}}}
|Unit III|Sequence Processing|9|
HMM PoS Tagging -- CRF NE Recognizer -- Naive Bayes Classifiers -- NB for Sentiment Analysis -- RNN: Language Models -- Sequence Labeling -- Sequence Classification -- Language Generation -- Stacked RNN bi-directional

{{{unit}}}
|Unit IV|Semantic Analysis |9| 
Computational Desiderata for Representations -- Model-Theoretic Semantics -- First-Order Logic -- Description Logics -- Word Senses -- Senses Relations -- WordNet -- Word Sense Disambiguation -- Feature-based WSD -- Knowledge-based WSD -- Lexical Semantics -- Semantic Roles -- Diathesis Alternations -- Problems with Thematic Roles -- Proposition Bank -- FrameNet -- Semantic Role Labeling

{{{unit}}}
|Unit V|Text Analysis with Python|9|
Tokenizer -- Vectorizing text using Gensim -- n-grams -- Word2Vec -- GloVe -- PoS Tagging -- Dependency Parsing -- Text classification using deep neural networks: IMDB sentiment analysis -- Word Similarity

\hfill *Total: 45*

** Course Outcomes
After the completion of this course, students will be able to: 
- Describe the language models (K2)
- Explain levels of knowledge in language processing (K2)
- Write Python programs for text processing (K3)
- Apply NLP techniques to MT, IR and IE systems (K3)
 
     
** References
1. Daniel Jurafsky and James H Martin, “Speech and Language Processing”, 3rd Edition, https://web.stanford.edu/~jurafsky/slp3/
2. Bhargav Srinivasa-Desikan, "Natural Language Processing and Computational Linguistics-A practical guide to text analysis with Python, Gensim, spaCy and Keras", Packt Publishing, 2018
3. Steven Bird, Ewan Klein, and Edward Loper, “Natural Language Processing with Python”, O’Reilly, 2009.
4. Christopher D. Manning, Hinrich Schutze, Foundations of Statistical Natural Language Processing, MIT Press, 1999.
5. Nitin Indurkhya, Fred J. Damerau, Handbook of Natural Language Processing, 2nd Edition, CRC Press, 2010.
