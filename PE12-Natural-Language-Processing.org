* <<<CP1224>>> NATURAL LANGUAGE PROCESSING
:Properties:
:author:  B Senthil Kumar, D Thenmozhi
:date: 06 May 2022
:end:

#+startup: showall

{{{credits}}}
|L|T|P|C|
|3|0|0|3|

** Course Objectives
- To learn the language models.
- To understand the levels of knowledge in language processing.
- To understand sequence processing of text. 
- To explore text processing using Python.


{{{unit}}}
|Unit I |Language Modeling and Vector Semantics|10| 
Introduction: Knowledge in Language Processing -- Ambiguity; Text Normalization -- N-grams 
-- Evaluating language model -- Sampling -- Generalization -- Smoothing -- Vector Semantics: 
Words and vectors -- Cosine similarity -- TF-IDF -- PPMI -- Word2Vec -- Semantic properties 
of embeddings -- Evaluating vector model; Neural language model: Feedforward networks for NLP -- 
Feedforward Neural Language Modeling -- Training the neural language model

{{{unit}}} 
|Unit II|Word Level and Syntactic Analysis|9| 
English Word Classes -- Part-of-Speech Tagging -- Named Entities -- NE Tagging -- 
Context-free grammar -- Grammar rules for Engligh -- Treebanks -- Constituency Parsing:
 Ambiguity -- CKY Parsing -- Neural Constituency Parsing -- Dependency Parsing: 
 Dependency Relations -- Formalisms -- Transition-based and Graph-based Dependency Parsing

{{{unit}}}
|Unit III|Sequence Processing|8|
HMM PoS Tagging -- CRF NE Recognizer -- Naive Bayes Classifiers -- NB for Sentiment 
Analysis -- RNN: Language Models -- Sequence Labeling -- Sequence Classification -- 
Language Generation -- Stacked and Bidirectional

{{{unit}}}
|Unit IV|Semantic Analysis |10| 
Computational Desiderata for Representations -- Model-Theoretic Semantics -- 
First-Order Logic -- Description Logics -- Word Senses -- Senses Relations -- WordNet 
-- Word Sense Disambiguation -- Feature-based WSD -- Knowledge-based WSD -- Lexical Semantics 
-- Semantic Roles -- Diathesis Alternations -- Problems with Thematic Roles -- 
Proposition Bank -- FrameNet -- Semantic Role Labeling

{{{unit}}}
|Unit V|Text Analysis with Python|8|
Tokenizer -- Vectorizing text -- BoW -- Tf-idf -- n-grams -- Word2Vec -- GloVe -- PoS Tagging 
-- Dependency Parsing -- Text classification using deep neural networks -- Word Similarity

\hfill *Total: 45*

** Course Outcomes
After the completion of this course, students will be able to: 
- Apply the vector semantics in language modeling (K3)
- Apply the levels of knowledge in language processing (K3)
- Explain the Sequence processing with ML/Neural networks. (K2)
- Apply Python for Text Analysis (K3)
 
     
** References
1. Daniel Jurafsky and James H Martin, “Speech and Language Processing”, 3rd Edition, https://web.stanford.edu/~jurafsky/slp3/
2. Bhargav Srinivasa-Desikan, "Natural Language Processing and Computational Linguistics-A practical guide to text analysis with Python, Gensim, spaCy and Keras", Packt Publishing, 2018
3. Steven Bird, Ewan Klein, and Edward Loper, “Natural Language Processing with Python”, O’Reilly, 2009.
4. Christopher D. Manning, Hinrich Schutze, Foundations of Statistical Natural Language Processing, MIT Press, 1999.
5. Nitin Indurkhya, Fred J. Damerau, Handbook of Natural Language Processing, 2nd Edition, CRC Press, 2010.
